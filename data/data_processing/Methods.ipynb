{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG3X-tGIpkMA"
      },
      "source": [
        "# AI/ML methods notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMEmAFI5sAuC"
      },
      "source": [
        "# install Python packages\n",
        "This notebook is equipped with a dedicated login shell, tailored to the environment in which it is executed. If you are utilizing your personal compute system, such as a laptop, the login corresponds to your individual compute system login. Conversely, when running this notebook on Google Colab, the login is attributed to the root user. The initiation of Linux shell commands within Jupyter notebook code cells is denoted by a preceding exclamation point (!).\n",
        "\n",
        "In the code cell below, the provided pip commands are employed to install a range of Python libraries essential for the tasks covered in this notebook. It's worth noting that additional Python libraries are automatically installed within our virtual environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbm2EcyIs_i"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb8-MziuOeFs",
        "outputId": "3a6ffae5-753d-4072-eb73-f1dd6064ef94"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn --no-cache\n",
        "!pip install scanpy --no-cache\n",
        "!pip install gseapy --no-cache\n",
        "!pip install pydeseq2 --no-cache\n",
        "!pip install pybiomart==0.1 --no-cache\n",
        "!pip install mygene --no-cache\n",
        "!pip install sklearn_som  --no-cache\n",
        "!pip install pandas --no-cache\n",
        "!pip install numpy --no-cache\n",
        "!pip install matplotlib --no-cache\n",
        "!pip install sklearn-som --no-cache\n",
        "!pip install pyDeseq2 --no-cache\n",
        "!pip install Ensembl_converter --no-cache\n",
        "!pip install mygene --no-cache\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpkDoGrUsMlL"
      },
      "source": [
        "# import Python modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSnhzxTaLN9l"
      },
      "source": [
        "This notebook imports a number of Python modules for use in several notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f079g46t5jTU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn_som.som import SOM\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import scanpy as sc\n",
        "import gseapy as gp\n",
        "from gseapy.plot import gseaplot\n",
        "from pydeseq2.dds import DeseqDataSet\n",
        "from pydeseq2.ds import DeseqStats\n",
        "from gseapy import Msigdb\n",
        "from pybiomart import Server\n",
        "import mygene\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import TweedieRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from math import log\n",
        "import statsmodels.api as sm\n",
        "import pylab\n",
        "import operator\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from itertools import islice\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import scipy.stats as stats\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from Ensembl_converter import EnsemblConverter\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance\n",
        "#from vega_datasets import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxokeQF9rjFG"
      },
      "source": [
        "# define misc helper methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_cXRde853Lu"
      },
      "source": [
        "# Define data ingestion methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCSHct2Opf8X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwoDZ49r7i_6"
      },
      "outputs": [],
      "source": [
        "def read_meta_data(dataset):\n",
        "  # dataset=255\n",
        "  url = 'https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=OSD-' + dataset + '_metadata_OSD-' + dataset + '-ISA.zip'\n",
        "  filename = dataset + '-meta.zip'\n",
        "  urlretrieve(url, filename)\n",
        "  !unzip -o {filename} > /dev/null\n",
        "  df = pd.read_csv('s_OSD-' + dataset + '.txt', sep='\\t', header=0)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQxRBfUs6Ir"
      },
      "outputs": [],
      "source": [
        "def read_rnaseq_data(data):\n",
        "  # data = '255_rna_seq_Normalized_Counts'\n",
        "  dataset = data.split('_')[0]\n",
        "  url='https://osdr.nasa.gov/geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=GLDS-' + data + '.csv'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCVR-HkZn08K"
      },
      "outputs": [],
      "source": [
        "def read_phenotype_data(dataset, data):\n",
        "  # dataset = '557'\n",
        "  # data = 'LSDS-1_immunostaining_microscopy_PNAtr_Transformed_Reusable_Results'\n",
        "  url='https://osdr.nasa.gov//geode-py/ws/studies/OSD-' + str(dataset) + '/download?source=datamanager&file=' + data + '.csv'\n",
        "  df = pd.read_csv(url)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ga9Pbi5rr1R"
      },
      "source": [
        "# define data filtering methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJaculrSRZp_"
      },
      "outputs": [],
      "source": [
        "def filter_cvs(df, thresh=0.5):\n",
        "\n",
        "  # calculate coefficient of variation\n",
        "  cvs=list()\n",
        "  for i in range(len(df)):\n",
        "    m=np.mean(df.iloc[i][1:])\n",
        "    sd=np.std(df.iloc[i][1:])\n",
        "    cvs.append(sd/m)\n",
        "\n",
        "  # plot hist of dist of coev of variation\n",
        "  # fig, axs = plt.subplots()\n",
        "  # axs.hist(cvs, bins=20)\n",
        "\n",
        "  # keep genes with cv > thresh\n",
        "  indices = list()\n",
        "  for i in range(len(cvs)):\n",
        "    if cvs[i] > thresh:\n",
        "      indices.append(i)\n",
        "  return df.iloc[indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kMwy7X10hxR"
      },
      "outputs": [],
      "source": [
        "def drop_nans(df):\n",
        "  # drop NaN rows\n",
        "  df.dropna(inplace=True)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1tNC979OtBg"
      },
      "outputs": [],
      "source": [
        "def drop_lowcount(df, threshold=10):\n",
        "\n",
        "  # let's drop any low-count genes\n",
        "  print(len(df))\n",
        "  if 'transcript' in df.columns:\n",
        "    df = df[df.drop(columns=['transcript']).sum(axis=1) >= threshold]\n",
        "  elif 'Unnamed: 0' in df.columns:\n",
        "    df = df[df.drop(columns=['Unnamed: 0']).sum(axis=1) >= threshold]\n",
        "    #df.rename(columns={\"Unnamed: 0\":\"transcript\"}, inplace=True)\n",
        "  else:\n",
        "    raise Exception(\"check file format\")\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LegH26QSPhp7"
      },
      "outputs": [],
      "source": [
        "def filter_genes(df):\n",
        "  # let's filter protein/ non-protein-coding genes\n",
        "  server = Server(host='http://www.ensembl.org')\n",
        "  dataset = (server.marts['ENSEMBL_MART_ENSEMBL'].datasets['mmusculus_gene_ensembl'])\n",
        "  gene_info = dataset.query(attributes=['ensembl_gene_id', 'external_gene_name', 'gene_biotype'])\n",
        "  gene_info.columns = ['Gene stable ID', 'Gene name', 'Gene type']\n",
        "\n",
        "  rna = df\n",
        "  genes = gene_info[gene_info[\"Gene type\"] == \"protein_coding\"]\n",
        "\n",
        "  rna_gene_ids = set(rna[\"Unnamed: 0\"])\n",
        "  protein_coding_gene_ids = set(genes[\"Gene stable ID\"])\n",
        "\n",
        "  common_genes = rna_gene_ids.intersection(protein_coding_gene_ids)\n",
        "\n",
        "  common_genes_df = rna[rna[\"Unnamed: 0\"].isin(common_genes)]\n",
        "\n",
        "  print(f\"Number of protein coding genes: {len(common_genes)}\")\n",
        "\n",
        "  return common_genes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIopMUVv2jpH"
      },
      "outputs": [],
      "source": [
        "def filter_data(df, dropnans=False, dropgenes=False, droplowcvs=0, droplowcount=0):\n",
        "  # drop non protein-coding genes\n",
        "  if dropgenes:\n",
        "    df = filter_genes(df)\n",
        "  # drop NANs\n",
        "  if dropnans:\n",
        "    df = drop_nans(df)\n",
        "  # drop low coef of var genes\n",
        "  if droplowcvs != 0:\n",
        "    df = filter_cvs(df, droplowcvs)\n",
        "  if droplowcount != 0:\n",
        "    df = drop_lowcount(df, droplowcount)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7grY5F-aEG_6"
      },
      "outputs": [],
      "source": [
        "def exclude_samples_by_prefix(df, prefix=\"V\", colname=\"Source Name\"):\n",
        "  sample_names=list(df[colname].values)\n",
        "  exclude_names=list()\n",
        "  for sn in sample_names:\n",
        "    if sn.startswith(prefix):\n",
        "      exclude_names.append(sn)\n",
        "  return exclude_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYp-9Ytt70y7"
      },
      "outputs": [],
      "source": [
        "def intersect_samples(A_list, B_list):\n",
        "  samples_A_dict = dict()\n",
        "  samples_B_list = list()\n",
        "  for i in range(len(A_list)):\n",
        "    sample = A_list[i]\n",
        "    num = \"\"\n",
        "    for c in sample:\n",
        "      if c.isdigit():\n",
        "        num += str(c)\n",
        "    if \"G\" in sample:\n",
        "      samples_A_dict[\"GC\" + num] = A_list[i]\n",
        "\n",
        "    elif \"F\" in sample:\n",
        "      samples_A_dict[\"F\" + num] = A_list[i]\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  for sample in B_list:\n",
        "    num = \"\"\n",
        "    for c in sample:\n",
        "      if c.isdigit():\n",
        "        num += str(c)\n",
        "    if \"G\" in sample:\n",
        "      samples_B_list.append(\"GC\" + num)\n",
        "    elif \"F\" in sample:\n",
        "      samples_B_list.append(\"F\" + num)\n",
        "    else:\n",
        "      continue\n",
        "  # intersect A samples with B  samples\n",
        "  samples_both=list(set(samples_A_dict.keys()) & set(samples_B_list))\n",
        "  return samples_both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4IuHC13rGZv"
      },
      "source": [
        "# data transformation methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFOBNzQ-rIW4"
      },
      "outputs": [],
      "source": [
        "def transpose_df(df, cur_index_col, new_index_col):\n",
        "  df = df.set_index(cur_index_col).T\n",
        "  df.reset_index(level=0, inplace=True)\n",
        "  cols = [new_index_col] + list(df.columns)[1:]\n",
        "  df.columns = cols\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jVaYnW9rRTU"
      },
      "outputs": [],
      "source": [
        "def reduce_dims(df, current_key, new_key, n):\n",
        "  #df_t = transpose_df(df, current_key, new_key)\n",
        "  #sdList = df_t.var(axis=1)\n",
        "  sdList = df.std(axis=1)\n",
        "  print('len of sdlist: ', str(len(sdList)))\n",
        "  sdDict = {k: v for v, k in enumerate(sdList)}\n",
        "  if n < 0:\n",
        "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=False)\n",
        "  else:\n",
        "    sdDictSorted = sorted(sdDict.items(), key=operator.itemgetter(0), reverse=True)\n",
        "  topN = sdDictSorted[0:abs(n)]\n",
        "  print('n: ', n)\n",
        "  indices = [x[1] for x in topN]\n",
        "  #df_t = df_t.iloc[indices]\n",
        "  #df_tt= transpose_df(df_t, new_key, current_key)\n",
        "  return df.iloc[indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kip2oJPk9ArZ"
      },
      "outputs": [],
      "source": [
        "def convert_pd_to_np(df):\n",
        "  X=list()\n",
        "  for col in df.columns[1:]:\n",
        "    X.append(list(df[col]))\n",
        "  return np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqWeNhESyd5z"
      },
      "outputs": [],
      "source": [
        "def get_symbol_from_id(gene_id_list):\n",
        "  # Create an instance of EnsemblConverter\n",
        "  converter = EnsemblConverter()\n",
        "\n",
        "  # Convert Ensembl IDs to gene symbols\n",
        "  result = converter.convert_ids(gene_id_list)\n",
        "\n",
        "  # Print the resulting DataFrame\n",
        "  gene_symbol_list = list()\n",
        "  for i in range(len(result)):\n",
        "    gene_symbol_list.append(result.iloc[i]['Symbol'])\n",
        "\n",
        "  return gene_symbol_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYvmAZ627HKz"
      },
      "source": [
        "# plotting methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EozbsWlf7Lf4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plotbox_and_stats(data_, sample_key, field, treatment, space, exclude_samples=[]):\n",
        "  print('field: ', field)\n",
        "  print('excluding samples: ', exclude_samples)\n",
        "  fieldValues = set(data_[field])\n",
        "  value_dict=dict()\n",
        "  results = dict()\n",
        "\n",
        "  flight = str(field) + '_flight'\n",
        "  nonflight= str(field) + '_nonflight'\n",
        "  results[field] = dict()\n",
        "  value_dict[flight] = list()\n",
        "  value_dict[nonflight] = list()\n",
        "  for i in range(len(data_)):\n",
        "    if data_.iloc[i][sample_key] in exclude_samples:\n",
        "      continue\n",
        "    elif treatment is None:\n",
        "      if data_.iloc[i][sample_key].startswith('F'):\n",
        "        value_dict[flight].append(data_.iloc[i][field])\n",
        "      else:\n",
        "        value_dict[nonflight].append(data_.iloc[i][field])\n",
        "    else:\n",
        "      if data_.iloc[i][treatment] == space:\n",
        "        value_dict[flight].append(data_.iloc[i][field])\n",
        "      else:\n",
        "        value_dict[nonflight].append(data_.iloc[i][field])\n",
        "\n",
        "\n",
        "  if len(value_dict[flight]) != 0 and len(value_dict[nonflight]) != 0:\n",
        "    results[field]['t-test p-value'] = float('%.5f' % (stats.ttest_ind(value_dict[flight], value_dict[nonflight], equal_var=False).pvalue))\n",
        "    #results[field]['wilcoxon p-value'] = float('%.5f' % (stats.ranksums(value_dict[flight], value_dict[nonflight]).pvalue))\n",
        "    #results[field]['ks-test p-value'] = float('%.5f' % (stats.kstest(value_dict[flight], value_dict[nonflight]).pvalue))\n",
        "\n",
        "\n",
        "  print(results)\n",
        "  print('n flight = ', len(value_dict[flight]))\n",
        "  print('n flight = ', len(value_dict[flight]))\n",
        "  print('n nonflight = ', len(value_dict[nonflight]))\n",
        "  print('std nonflight = ', value_dict[nonflight].std())\n",
        "  fig,ax = plt.subplots()\n",
        "  ax.boxplot(value_dict.values())\n",
        "  ax.set_xticklabels(value_dict.keys())\n",
        "  #plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
        "  plt.xticks(rotation=30, ha='right')\n",
        "\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UrOPfUfTfXs"
      },
      "source": [
        "# machine learning methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt9z5IEuTh4F"
      },
      "outputs": [],
      "source": [
        "# define a method to run the k-means algorithm and then print which cluster each sample belongs to\n",
        "def my_kmeans(df, metadata, k):\n",
        "  # convert df to np\n",
        "  X = convert_pd_to_np(df)\n",
        "  kmeans = KMeans(n_clusters=k, random_state=42, init=\"k-means++\").fit(X)\n",
        "  # and predict each sample\n",
        "  samples = df.columns[1:]\n",
        "  for sample in samples:\n",
        "    print('sample: ', sample, ', cluster: ', kmeans.predict([list(df[sample])]), metadata[metadata['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgUckMDpTl-p"
      },
      "outputs": [],
      "source": [
        "# define a method that graphs the within-cluster-sum-of-squares metric to determine the optimum value of k (the elbow method)\n",
        "def find_k_elbow(df):\n",
        "  # convert df to np\n",
        "  X = convert_pd_to_np(df)\n",
        "  wcss = []\n",
        "  for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init=i)\n",
        "    kmeans.fit(X)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "  # plot wcss\n",
        "  x=[i for i in range(1, 11)]\n",
        "  y=wcss\n",
        "\n",
        "  plt.scatter(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NInCRFVjoQdE"
      },
      "outputs": [],
      "source": [
        "def my_gmm(df, metadata, k):\n",
        "  # convert df to np\n",
        "  #df=data['255-normalized']\n",
        "  X = convert_pd_to_np(df)\n",
        "  gm = GaussianMixture(n_components=k, random_state=42).fit(X)\n",
        "  # and predict each sample\n",
        "  samples = df.columns[1:]\n",
        "  # predict probability\n",
        "  for sample in samples:\n",
        "    print('sample: ', sample, ', cluster: ', gm.predict([list(df[sample])]), metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0])\n",
        "  return gm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FVERHbDoRXW"
      },
      "outputs": [],
      "source": [
        "def find_gmm_elbow(df):\n",
        "  X = convert_pd_to_np(df)\n",
        "  n_components=range(1, 11)\n",
        "  models = [GaussianMixture(n, n_init=42).fit(X) for n in n_components]\n",
        "  aics = [model.aic(X) for model in models]\n",
        "  bics = [model.bic(X) for model in models]\n",
        "  plt.figure(dpi=100)\n",
        "  plt.plot(n_components, aics, label='AIC')\n",
        "  plt.plot(n_components, bics, label='BIC')\n",
        "  plt.legend(loc='best')\n",
        "  plt.xlabel('n_components')\n",
        "  plt.ylabel('AIC or BIC')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VHHZRwjpvgu"
      },
      "source": [
        "# Differential gene expression analysis methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAIDHbhepzIO"
      },
      "outputs": [],
      "source": [
        "def map_samples_to_conditions(dfT, metadata, metadata_condition_param, condition_0, condition_1):\n",
        "  # map conditions to samples for comparison in DESeq2\n",
        "  condition_dict=dict()\n",
        "  for sample in list(dfT['sample']):\n",
        "    #val=metadata['255'][metadata['255']['Sample Name']==sample]['Factor Value[Spaceflight]'].values[0]\n",
        "    val=metadata[metadata['Sample Name']==sample][metadata_condition_param].values[0]\n",
        "\n",
        "    if val == condition_0:\n",
        "      condition_dict[sample] = 0\n",
        "    else:\n",
        "      condition_dict[sample] = 1\n",
        "\n",
        "\n",
        "  dfT[\"condition\"] = dfT[\"sample\"].map(condition_dict)\n",
        "  conditions=dfT[['sample', 'condition']]\n",
        "\n",
        "  return conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtFctCTHqdhm"
      },
      "outputs": [],
      "source": [
        "def run_deseq2(df, metadata):\n",
        "  # transpose df\n",
        "  dfT = df.T\n",
        "  dfT.columns=dfT.iloc[0]\n",
        "  dfT=dfT.iloc[1:]\n",
        "  dfT.columns.name=None\n",
        "  dfT = dfT.reset_index().rename(columns={\"index\":\"sample\"})\n",
        "\n",
        "  # map conditions\n",
        "  conditions = map_samples_to_conditions(dfT, metadata, 'Factor Value[Spaceflight]', 'Ground Control', 'Space Flight')\n",
        "\n",
        "  # get count data set up for DESeq2\n",
        "  counts=dfT.drop(columns=['sample', 'condition']).reset_index(drop=True)\n",
        "  counts.applymap(np.isreal)\n",
        "  counts=counts.astype(int)\n",
        "\n",
        "  # run DESeq2\n",
        "  dds=DeseqDataSet(counts=counts, metadata=conditions, design_factors=\"condition\")\n",
        "  dds.deseq2()\n",
        "\n",
        "  return dds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtkM88XOqz55"
      },
      "outputs": [],
      "source": [
        "def get_results(dds):\n",
        "  # do DGEA\n",
        "  stats_results=DeseqStats(dds, contrast = ('condition', '0', '1'))\n",
        "\n",
        "  # run summary\n",
        "  stats_results.summary()\n",
        "\n",
        "  # get differentially expressed genes\n",
        "  res = stats_results.results_df\n",
        "\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTT1I17Ardvq"
      },
      "outputs": [],
      "source": [
        "def get_sig_genes(res, pval=0.05, l2fc=0):\n",
        "  sigs = res[(res.padj < pval) & (abs(res.log2FoldChange) > l2fc)]\n",
        "  return sigs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtkWQuXmrvuI"
      },
      "outputs": [],
      "source": [
        "def get_dge_ranked_genes(res):\n",
        "  # rank genes from most to least significantly differentially expressed\n",
        "  ranking = res[['stat']].dropna().sort_values('stat', ascending=False)\n",
        "  ranking_index=list(ranking.index)\n",
        "  ranking_index_upper=[x.upper() for x in ranking_index]\n",
        "  ranking.index=ranking_index_upper\n",
        "\n",
        "  return ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjjASIsmgRx3"
      },
      "outputs": [],
      "source": [
        "def filter_by_dgea(data, metadata,  pval, l2fc):\n",
        "  # run DESeq2\n",
        "  dds = run_deseq2(data, metadata)\n",
        "\n",
        "  # get results\n",
        "  res = get_results(dds)\n",
        "\n",
        "  # get sig genes\n",
        "  sig_genes_df = get_sig_genes(res, pval=pval, l2fc=l2fc)\n",
        "\n",
        "  # get top sig genes\n",
        "  top_genes = list(sig_genes_df.sort_values('padj').index)\n",
        "\n",
        "  # filter data by topn_genes\n",
        "  return data[data['Unnamed: 0'].isin(top_genes)]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
